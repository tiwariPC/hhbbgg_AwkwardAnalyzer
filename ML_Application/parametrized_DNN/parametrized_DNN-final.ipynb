{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30409ab8",
   "metadata": {},
   "source": [
    "# Parametrized DNN\n",
    "parametrized DNN \n",
    "1. Plot signal and background seperation\n",
    "2. Include all signals\n",
    "2. check the backgrounds.\n",
    "3. Check the AUC score as this is coming 1\n",
    "4. Improve the training\n",
    "5. include the weight of preselection\n",
    "6. Weights for signal and background to negate the class imbalance\n",
    "7. Plot the DNN score for each sample. \n",
    "8. Event categorization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3c41b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X300_Y200/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X300_Y300/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X300_Y400/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X300_Y500/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X400_Y300/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X400_Y400/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X400_Y500/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X500_Y400/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X500_Y500/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X550_Y500/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X600_Y500/nominal/NOTAG_merged.parquet does not exist.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import uproot\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Taking mass X and corresponding Y mass points\n",
    "# mass_points = [300, 400, 500, 550, 600, 650, 700, 900, 1000, 1200, 1400, 1600, 1800, 2000, 2500, 3000, 3500, 4000]  # Example mass points\n",
    "# y_values = [ 60, 70, 80, 90, 95, 100, 125, 150, 200, 300, 400, 500, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2600, 3000, 3500]  # Example Y values\n",
    "\n",
    "mass_points = [300, 400, 500, 550, 600, 650, 700, 900, 1000]  #  mass points\n",
    "y_values = [ 100, 125, 150, 200, 300, 400, 500]  #  Y values\n",
    "\n",
    "\n",
    "\n",
    "# Load signal data from Parquet files\n",
    "signal_data = []\n",
    "for mass in mass_points:\n",
    "    for y in y_values:\n",
    "        file_path = f\"../../../output_parquet/final_production_Syst/merged/NMSSM_X{mass}_Y{y}/nominal/NOTAG_merged.parquet\"\n",
    "        \n",
    "        if os.path.exists(file_path):  # Check if file exists\n",
    "            try:\n",
    "                df = pd.read_parquet(file_path)  # Load the Parquet file\n",
    "                df[\"mass\"] = mass  \n",
    "                df[\"y_value\"] = y  # Store Y value if needed\n",
    "                df[\"label\"] = 1  # Assuming signal label\n",
    "                signal_data.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not read {file_path}. Error: {e}\")\n",
    "        else:\n",
    "            print(f\"Warning: File {file_path} does not exist.\")\n",
    "\n",
    "# Combine all signal data into a single DataFrame\n",
    "signal_df = pd.concat(signal_data, ignore_index=True) if signal_data else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ace5651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346281, 853)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9c83e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load background data from ROOT files\n",
    "background_files = [\n",
    "    (\"../../outputfiles/hhbbgg_analyzer-v2-trees.root\", # Load background data from ROOT files\n",
    "background_files = [\n",
    "    (\"../../outputfiles/hhbbgg_analyzer-v2-trees.root\", \"/GGJets/preselection\"),\n",
    "    (\"../../outputfiles/hhbbgg_analyzer-v2-trees.root\", \"/GJetPt20To40/preselection\"),\n",
    "    (\"../../outputfiles/hhbbgg_analyzer-v2-trees.root\", \"/GJetPt40/preselection\"),\n",
    "#     (\"../../outputfiles/hhbbgg_analyzer-v2-trees.root\", \"/GGJets/preselection\"),\n",
    "#     (\"../../outputfiles/hhbbgg_analyzer-v2-trees.root\", \"/GJetPt20To40/preselection\"),\n",
    "#     (\"../../outputfiles/hhbbgg_analyzer-v2-trees.root\", \"/GJetPt40/preselection\"),\n",
    "]\n",
    "background_data = []\n",
    "for file_path, tree_name in background_files:\n",
    "    try:\n",
    "        with uproot.open(file_path) as file:\n",
    "            tree = file[tree_name]\n",
    "            df = tree.arrays(library=\"pd\")\n",
    "            df[\"mass\"] = np.random.choice(mass_points, len(df))  # Random mass assignment\n",
    "            df[\"label\"] = 0\n",
    "            background_data.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not read {file_path}. Error: {e}\")\n",
    "\n",
    "df_background = pd.concat(background_data, ignore_index=True) if background_data else pd.DataFrame()\"),\n",
    "    (\"../../outputfiles/hhbbgg_analyzer-v2-trees.root\", \"/GJetPt20To40/preselection\"),\n",
    "    (\"../../outputfiles/hhbbgg_analyzer-v2-trees.root\", \"/GJetPt40/preselection\"),\n",
    "#     (\"../../outputfiles/hhbbgg_analyzer-v2-trees.root\", \"/GGJets/preselection\"),\n",
    "#     (\"../../outputfiles/hhbbgg_analyzer-v2-trees.root\", \"/GJetPt20To40/preselection\"),\n",
    "#     (\"../../outputfiles/hhbbgg_analyzer-v2-trees.root\", \"/GJetPt40/preselection\"),\n",
    "]\n",
    "background_data = []\n",
    "for file_path, tree_name in background_files:\n",
    "    try:\n",
    "        with uproot.open(file_path) as file:\n",
    "            tree = file[tree_name]\n",
    "            df = tree.arrays(library=\"pd\")\n",
    "            df[\"mass\"] = np.random.choice(mass_points, len(df))  # Random mass assignment\n",
    "            df[\"label\"] = 0\n",
    "            background_data.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not read {file_path}. Error: {e}\")\n",
    "\n",
    "df_background = pd.concat(background_data, ignore_index=True) if background_data else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5521617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and labels\n",
    "features = [\n",
    "    # bbgg varaibles\n",
    "    'bbgg_eta', 'bbgg_phi',\n",
    "    # Photon variables\n",
    "    'lead_pho_phi', 'sublead_pho_eta', 'sublead_pho_phi',\n",
    "    # Diphoton variables\n",
    "    'diphoton_eta', 'diphoton_phi',\n",
    "    # dibjet variables\n",
    "    'dibjet_eta', 'dibjet_phi', \n",
    "    # bjet kinematics\n",
    "    'lead_bjet_pt', 'sublead_bjet_pt', 'lead_bjet_eta', 'lead_bjet_phi', 'sublead_bjet_eta', \n",
    "    'sublead_bjet_phi', 'sublead_bjet_PNetB', 'lead_bjet_PNetB', \n",
    "    # collion-sopper frame variables.\n",
    "    'CosThetaStar_gg', \n",
    "    'CosThetaStar_jj', 'CosThetaStar_CS', \n",
    "    # Delta (jg, min)\n",
    "    'DeltaR_jg_min',\n",
    "    # Ratios\n",
    "    'pholead_PtOverM', 'phosublead_PtOverM',\n",
    "    # Pho mvaID\n",
    "    'lead_pho_mvaID', 'sublead_pho_mvaID'\n",
    "]\n",
    "features.extend([\"mass\", \"y_value\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b6ed8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bbgg_eta',\n",
       " 'bbgg_phi',\n",
       " 'lead_pho_phi',\n",
       " 'sublead_pho_eta',\n",
       " 'sublead_pho_phi',\n",
       " 'diphoton_eta',\n",
       " 'diphoton_phi',\n",
       " 'dibjet_eta',\n",
       " 'dibjet_phi',\n",
       " 'lead_bjet_pt',\n",
       " 'sublead_bjet_pt',\n",
       " 'lead_bjet_eta',\n",
       " 'lead_bjet_phi',\n",
       " 'sublead_bjet_eta',\n",
       " 'sublead_bjet_phi',\n",
       " 'sublead_bjet_PNetB',\n",
       " 'lead_bjet_PNetB',\n",
       " 'CosThetaStar_gg',\n",
       " 'CosThetaStar_jj',\n",
       " 'CosThetaStar_CS',\n",
       " 'DeltaR_jg_min',\n",
       " 'pholead_PtOverM',\n",
       " 'phosublead_PtOverM',\n",
       " 'lead_pho_mvaID',\n",
       " 'sublead_pho_mvaID',\n",
       " 'mass',\n",
       " 'y_value']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91c139ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random mass + y_value assignment for backgrounds (ensure this was done earlier!)\n",
    "df_background[\"mass\"] = np.random.choice(mass_points, len(df_background))\n",
    "df_background[\"y_value\"] = np.random.choice(y_values, len(df_background))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "458d6ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reduce background dataset size by random sampling\n",
    "background_fraction = 1 #  20% of the background\n",
    "df_background = df_background.sample(frac=background_fraction, random_state=42)\n",
    "\n",
    "# Combine signal and background\n",
    "df_combined = pd.concat([signal_df, df_background], ignore_index=True)\n",
    "\n",
    "# checking df_combined is not empty\n",
    "if df_combined.empty:\n",
    "    raise ValueError(\"Error: Combined DataFrame is empty. Check input files.\")\n",
    "\n",
    "# Convert feature data to DataFrame to prevent AttributeError\n",
    "df_features = df_combined[features]\n",
    "\n",
    "# Fill missing values with column mean\n",
    "df_features = df_features.fillna(df_features.mean())\n",
    "\n",
    "# Extract features (X) and labels (y)\n",
    "X = df_features.values\n",
    "y = df_combined[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed93e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ['weight_preselection']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34ac841f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2011751, 27)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1feb7f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into 80% train, 20% test (stratified to maintain label distribution)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "## Adding weights\n",
    "# Compute class-balanced weights (sum of signal weights = 0.5, background = 0.5)\n",
    "def compute_class_normalized_weights(y):\n",
    "    signal_mask = y == 1\n",
    "    background_mask = y == 0\n",
    "\n",
    "    n_signal = np.sum(signal_mask)\n",
    "    n_background = np.sum(background_mask)\n",
    "\n",
    "    weights = np.zeros_like(y, dtype=np.float32)\n",
    "    weights[signal_mask] = 0.5 / n_signal\n",
    "    weights[background_mask] = 0.5 / n_background\n",
    "\n",
    "    return weights\n",
    "\n",
    "# Calculate weights for training and testing sets\n",
    "w_train = compute_class_normalized_weights(y_train)\n",
    "w_test = compute_class_normalized_weights(y_test)\n",
    "\n",
    "\n",
    "# Standardize features (Fit only on train, transform both)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  \n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create PyTorch datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create Dataloader for training\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Optional: Create test dataloader if you want batch evaluation\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a82fbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute weights\n",
    "train_weights = compute_class_normalized_weights(y_train)\n",
    "test_weights = compute_class_normalized_weights(y_test)\n",
    "\n",
    "# Convert to torch tensors\n",
    "train_weights_tensor = torch.tensor(train_weights, dtype=torch.float32)\n",
    "test_weights_tensor = torch.tensor(test_weights, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5ec4ef",
   "metadata": {},
   "source": [
    "# Checking -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b8d696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Start fresh from combined_df\n",
    "X_with_meta = df_combined[features + ['label', 'weight_preselection']].copy()\n",
    "\n",
    "# Split using stratification\n",
    "train_df, test_df = train_test_split(\n",
    "    X_with_meta, test_size=0.2, random_state=42, stratify=X_with_meta['label']\n",
    ")\n",
    "\n",
    "# Extract arrays\n",
    "X_train = train_df[features].values\n",
    "y_train = train_df['label'].values\n",
    "w_train = train_df['weight_preselection'].values\n",
    "\n",
    "X_test = test_df[features].values\n",
    "y_test = test_df['label'].values\n",
    "w_test = test_df['weight_preselection'].values\n",
    "\n",
    "# Normalize weights (signal sum = 0.5, background sum = 0.5)\n",
    "def normalize_weights(weights, labels):\n",
    "    sig_mask = labels == 1\n",
    "    bkg_mask = labels == 0\n",
    "    weights = np.array(weights, dtype=np.float32)\n",
    "\n",
    "    norm_weights = np.zeros_like(weights)\n",
    "    norm_weights[sig_mask] = 0.5 * weights[sig_mask] / np.sum(weights[sig_mask])\n",
    "    norm_weights[bkg_mask] = 0.5 * weights[bkg_mask] / np.sum(weights[bkg_mask])\n",
    "    return norm_weights\n",
    "\n",
    "train_weights = normalize_weights(w_train, y_train)\n",
    "test_weights = normalize_weights(w_test, y_test)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "train_weights_tensor = torch.tensor(train_weights, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "test_weights_tensor = torch.tensor(test_weights, dtype=torch.float32)\n",
    "\n",
    "# Create PyTorch datasets and dataloaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor, train_weights_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor, test_weights_tensor)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96fa259",
   "metadata": {},
   "source": [
    "# -------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a408f339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 300  400  500  550  600  650  700  900 1000]\n",
      "[ 650  600  300  900  700  550  500 1000  400]\n"
     ]
    }
   ],
   "source": [
    "# Checking\n",
    "\n",
    "print(signal_df[\"mass\"].unique())\n",
    "print(df_background[\"mass\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2c4ee6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['run', 'lumi', 'event', 'puppiMET_pt', 'puppiMET_phi',\n",
      "       'puppiMET_phiJERDown', 'puppiMET_phiJERUp', 'puppiMET_phiJESDown',\n",
      "       'puppiMET_phiJESUp', 'puppiMET_phiUnclusteredDown',\n",
      "       'puppiMET_phiUnclusteredUp', 'puppiMET_ptJERDown', 'puppiMET_ptJERUp',\n",
      "       'puppiMET_ptJESDown', 'puppiMET_ptJESUp', 'puppiMET_ptUnclusteredDown',\n",
      "       'puppiMET_ptUnclusteredUp', 'puppiMET_sumEt', 'lead_pho_pt',\n",
      "       'lead_pho_eta', 'lead_pho_phi', 'sublead_pho_pt', 'sublead_pho_eta',\n",
      "       'sublead_pho_phi', 'lead_bjet_pt', 'lead_bjet_eta', 'lead_bjet_phi',\n",
      "       'sublead_bjet_pt', 'sublead_bjet_eta', 'sublead_bjet_phi',\n",
      "       'dibjet_mass', 'diphoton_mass', 'bbgg_mass', 'dibjet_pt', 'diphoton_pt',\n",
      "       'bbgg_pt', 'bbgg_eta', 'bbgg_phi', 'DeltaPhi_j1MET', 'DeltaPhi_j2MET',\n",
      "       'Res_chi_t0', 'Res_chi_t1', 'lepton1_mvaID', 'lepton1_pt',\n",
      "       'lepton1_pfIsoId', 'n_jets', 'weight_central', 'weight_preselection',\n",
      "       'weight_selection', 'weight_srbbgg', 'weight_srbbggMET',\n",
      "       'weight_crbbantigg', 'weight_crantibbgg', 'weight_crantibbantigg',\n",
      "       'weight_sideband', 'weight_idmva_sideband', 'weight_idmva_presel',\n",
      "       'dibjet_eta', 'dibjet_phi', 'diphoton_eta', 'diphoton_phi',\n",
      "       'lead_bjet_PNetB', 'sublead_bjet_PNetB', 'pholead_PtOverM',\n",
      "       'phosublead_PtOverM', 'FirstJet_PtOverM', 'SecondJet_PtOverM',\n",
      "       'CosThetaStar_CS', 'CosThetaStar_jj', 'CosThetaStar_gg',\n",
      "       'DeltaR_jg_min', 'lead_pt_over_diphoton_mass',\n",
      "       'sublead_pt_over_diphoton_mass', 'lead_pt_over_dibjet_mass',\n",
      "       'sublead_pt_over_dibjet_mass', 'diphoton_bbgg_mass', 'dibjet_bbgg_mass',\n",
      "       'lead_pho_mvaID_WP90', 'lead_pho_mvaID_WP80', 'sublead_pho_mvaID_WP90',\n",
      "       'sublead_pho_mvaID_WP80', 'lead_pho_mvaID', 'sublead_pho_mvaID',\n",
      "       'preselection', 'selection', 'srbbgg', 'srbbggMET', 'crantibbgg',\n",
      "       'crbbantigg', 'crantibbantigg', 'sideband', 'idmva_sideband',\n",
      "       'idmva_presel', 'DeltaR_j1g1', 'DeltaR_j2g1', 'DeltaR_j1g2',\n",
      "       'DeltaR_j2g2', 'mass', 'label', 'y_value'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_background.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "258ea236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal y_value: [100 125 150 200 300 400 500]\n",
      "Background y_value: [100 200 500 300 150 125 400]\n"
     ]
    }
   ],
   "source": [
    "print(\"Signal y_value:\", signal_df[\"y_value\"].unique())\n",
    "print(\"Background y_value:\", df_background[\"y_value\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e01c9b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "class ParameterizedDNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ParameterizedDNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "#         self.model = nn.Sequential(\n",
    "#             nn.Linear(input_dim, 32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm1d(32),  # Helps stabilize training\n",
    "#             nn.Dropout(0.2),  # Reduce dropout\n",
    "\n",
    "#             nn.Linear(32, 16),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm1d(16),\n",
    "#             nn.Dropout(0.2),\n",
    "            \n",
    "#             nn.Linear(16, 8),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm1d(8),\n",
    "#             nn.Dropout(0.1),  # Lower dropout to retain information\n",
    "            \n",
    "#             nn.Linear(8, 1)  # Output layer (raw logits)\n",
    "#         )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4df3e456",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mass Distribution')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mass distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(signal_df['mass'], bins=20, alpha=0.5, label='Signal')\n",
    "plt.hist(df_background['mass'], bins=20, alpha=0.5, label='Background')\n",
    "plt.legend()\n",
    "plt.title(\"Mass Distribution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a71b2830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal shape (346281, 853) background.shape (1665470, 100)\n"
     ]
    }
   ],
   "source": [
    "# class balance\n",
    "print(\"signal shape\", signal_df.shape, \"background.shape\", df_background.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "882835a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor, train_weights_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78f209a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/50]\n",
      "Train Loss: nan | Train Acc: 0.8279 | Train AUC: 0.5000\n",
      "Test  Loss: nan | Test  Acc: 0.8279 | Test  AUC: 0.5000\n",
      "âœ… Model improved. Saved to: best_parametric_model.pt\n",
      "\n",
      "Epoch [2/50]\n",
      "Train Loss: nan | Train Acc: 0.8279 | Train AUC: 0.5000\n",
      "Test  Loss: nan | Test  Acc: 0.8279 | Test  AUC: 0.5000\n",
      "No improvement in AUC for 1 epoch(s).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/sraj/ipykernel_1107868/2364849717.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Initialize model\n",
    "input_dim = X.shape[1]\n",
    "model = ParameterizedDNN(input_dim)\n",
    "criterion = nn.BCEWithLogitsLoss()  # Expecting raw logits\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 50\n",
    "patience = 5\n",
    "best_auc = 0.0\n",
    "patience_counter = 0\n",
    "save_path = \"best_parametric_model.pt\"\n",
    "\n",
    "train_losses, train_accuracies, train_aucs = [], [], []\n",
    "fpr_all, tpr_all, thresholds_all = [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    y_true_train, y_pred_train = [], []\n",
    "\n",
    "    for X_batch, y_batch, w_batch in train_dataloader:\n",
    "        X_batch, y_batch, w_batch = X_batch.to(device), y_batch.to(device), w_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch).squeeze()\n",
    "\n",
    "        # ðŸ” Clamp logits to prevent sigmoid overflow\n",
    "        outputs = torch.clamp(outputs, min=-50.0, max=50.0)\n",
    "\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        weighted_loss = (loss * w_batch).mean()\n",
    "        weighted_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += weighted_loss.item()\n",
    "\n",
    "        # âœ… Safe prediction (remove NaNs if needed)\n",
    "        probs = torch.sigmoid(outputs).detach().cpu().numpy()\n",
    "        probs = np.nan_to_num(probs, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "        y_pred_train.extend(probs)\n",
    "        y_true_train.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    y_pred_train_binary = [1 if p > 0.5 else 0 for p in y_pred_train]\n",
    "    train_accuracy = accuracy_score(y_true_train, y_pred_train_binary)\n",
    "    y_pred_train = np.array(y_pred_train)\n",
    "    y_true_train = np.array(y_true_train)\n",
    "\n",
    "    # Safe AUC\n",
    "\n",
    "    train_auc = roc_auc_score(y_true_train, y_pred_train)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs_test = model(X_test_tensor.to(device)).squeeze()\n",
    "\n",
    "        # ðŸ” Clamp logits before sigmoid\n",
    "        outputs_test = torch.clamp(outputs_test, min=-50.0, max=50.0)\n",
    "\n",
    "        probs_test = torch.sigmoid(outputs_test).cpu().numpy()\n",
    "\n",
    "        # âœ… Clean predictions\n",
    "        probs_test = np.nan_to_num(probs_test, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "\n",
    "        test_loss = (criterion(outputs_test, y_test_tensor.to(device)) * test_weights_tensor.to(device)).mean().item()\n",
    "\n",
    "        y_pred_test_binary = [1 if p > 0.5 else 0 for p in probs_test]\n",
    "        test_accuracy = accuracy_score(y_test, y_pred_test_binary)\n",
    "        test_auc = roc_auc_score(y_test, probs_test)\n",
    "\n",
    "    train_losses.append(epoch_loss / len(train_dataloader))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_aucs.append(train_auc)\n",
    "\n",
    "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"Train Loss: {train_losses[-1]:.4f} | Train Acc: {train_accuracy:.4f} | Train AUC: {train_auc:.4f}\")\n",
    "    print(f\"Test  Loss: {test_loss:.4f} | Test  Acc: {test_accuracy:.4f} | Test  AUC: {test_auc:.4f}\")\n",
    "\n",
    "    # Early stopping based on test AUC\n",
    "    if test_auc > best_auc:\n",
    "        best_auc = test_auc\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"âœ… Model improved. Saved to: {save_path}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement in AUC for {patience_counter} epoch(s).\")\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"â›” Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# Load best model before proceeding\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "print(\"âœ… Best model loaded from checkpoint.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8201ae17",
   "metadata": {},
   "source": [
    "# Next step\n",
    "\n",
    "- [ ] Implement early stopping\n",
    "- [ ] Save the model\n",
    "- [ ] get the dNN score\n",
    "- [ ] Plot it like as in the approval of manos\n",
    "- [ ] Can also plot the signal and background seperations\n",
    "- [ ] Plot AUC\n",
    "- [ ] AUC, ROC\n",
    "- [ ] Signal and background separation\n",
    "- [ ] Check all variables. Include all variables \t\n",
    "- [ ] pNN transformed score\n",
    "- [ ] Plot feature importance \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab81588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Debugging\n",
    "interpolation_mass = 375  # between 300 and 400\n",
    "interpolation_y = 175     # between 150 and 200\n",
    "\n",
    "df_interp = df_background.sample(n=1000, random_state=42).copy()\n",
    "df_interp[\"mass\"] = interpolation_mass\n",
    "df_interp[\"y_value\"] = interpolation_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "505f99eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/matplotlib/axes/_axes.py:6826: RuntimeWarning: All-NaN slice encountered\n",
      "  xmin = min(xmin, np.nanmin(xi))\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/matplotlib/axes/_axes.py:6827: RuntimeWarning: All-NaN slice encountered\n",
      "  xmax = max(xmax, np.nanmax(xi))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "autodetected range of [nan, nan] is not finite",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/sraj/ipykernel_1054515/1272266922.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# 5. Plot output distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_interp_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Interpolated (MX={interpolation_mass}, MY={interpolation_y})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DNN Score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pNN Output at Interpolated Mass Point\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, data, **kwargs)\u001b[0m\n\u001b[1;32m   3222\u001b[0m     \u001b[0mBarContainer\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mPolygon\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBarContainer\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mPolygon\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m ]:\n\u001b[0;32m-> 3224\u001b[0;31m     return gca().hist(\n\u001b[0m\u001b[1;32m   3225\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m         \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1463\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001b[0m\n\u001b[1;32m   6852\u001b[0m             \u001b[0;31m# this will automatically overwrite bins,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6853\u001b[0m             \u001b[0;31m# so that each histogram uses the same bins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6854\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhist_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6855\u001b[0m             \u001b[0mtops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6856\u001b[0m         \u001b[0mtops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# causes problems later if it's an int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m    791\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ravel_and_check_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m     \u001b[0mbin_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniform_bins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_bin_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;31m# Histogram is an integer or a float array depending on the weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36m_get_bin_edges\u001b[0;34m(a, bins, range, weights)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`bins` must be positive, when an integer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mfirst_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_edge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_outer_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36m_get_outer_edges\u001b[0;34m(a, range)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mfirst_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_edge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_edge\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_edge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    324\u001b[0m                 \"autodetected range of [{}, {}] is not finite\".format(first_edge, last_edge))\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: autodetected range of [nan, nan] is not finite"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Choose an unseen MX, MY\n",
    "interpolation_mass = 375\n",
    "interpolation_y = 175\n",
    "\n",
    "# 2. Sample and set new param values\n",
    "df_interp = df_background.sample(n=1000, random_state=42).copy()\n",
    "df_interp[\"mass\"] = interpolation_mass\n",
    "df_interp[\"y_value\"] = interpolation_y\n",
    "\n",
    "# 3. Use the same features and preprocessing\n",
    "X_interp = df_interp[features].fillna(df_features.mean()).values\n",
    "X_interp = scaler.transform(X_interp)  # same scaler as training\n",
    "X_interp_tensor = torch.tensor(X_interp, dtype=torch.float32).to(device)\n",
    "\n",
    "# 4. Get model output\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_interp_pred = torch.sigmoid(model(X_interp_tensor)).cpu().numpy()\n",
    "\n",
    "# 5. Plot output distribution\n",
    "plt.hist(y_interp_pred, bins=50, alpha=0.7, label=f\"Interpolated (MX={interpolation_mass}, MY={interpolation_y})\")\n",
    "plt.xlabel(\"DNN Score\")\n",
    "plt.title(\"pNN Output at Interpolated Mass Point\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e7bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance(Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ee408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def compute_permutation_importance(model, X_val, y_val, mass_val, feature_names, device='cpu'):\n",
    "    model.eval()\n",
    "    X_val = X_val.clone().detach().to(device)\n",
    "    mass_val = mass_val.clone().detach().to(device)\n",
    "    y_val_np = y_val.cpu().numpy()\n",
    "\n",
    "    base_preds = torch.sigmoid(model(X_val, mass_val).squeeze()).detach().cpu().numpy()\n",
    "    base_auc = roc_auc_score(y_val_np, base_preds)\n",
    "\n",
    "    importances = []\n",
    "\n",
    "    for i in range(X_val.shape[1]):\n",
    "        scores = []\n",
    "        for _ in range(5):  # repeat for stability\n",
    "            X_shuffled = X_val.clone()\n",
    "            idx = torch.randperm(X_val.shape[0])\n",
    "            X_shuffled[:, i] = X_shuffled[idx, i]\n",
    "            preds = torch.sigmoid(model(X_shuffled, mass_val).squeeze()).detach().cpu().numpy()\n",
    "            auc = roc_auc_score(y_val_np, preds)\n",
    "            scores.append(base_auc - auc)  # performance drop\n",
    "        importances.append(np.mean(scores))\n",
    "\n",
    "    return np.array(importances)\n",
    "\n",
    "# Call the function\n",
    "importances = compute_permutation_importance(model, X_test_tensor, y_test_tensor, mass_test_tensor, feature_names, device=device)\n",
    "\n",
    "# Plot\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.barh(np.array(feature_names)[sorted_idx], importances[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance (AUC drop)\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Feature Importance (Permutation - Parametric DNN)\")\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5206b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c18ec0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41bcc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses.append(epoch_loss / len(train_dataloader))\n",
    "train_accuracies.append(train_accuracy)\n",
    "train_aucs.append(train_auc)\n",
    "\n",
    "# Add test AUC for plotting too\n",
    "if epoch == num_epochs - 1:\n",
    "    plt.plot(train_aucs, label='Train AUC')\n",
    "    plt.axhline(test_auc, color='red', linestyle='--', label='Test AUC (final)')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Train vs. Test AUC\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842b409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_pred_test[y_test == 1], bins=50, alpha=0.5, label='Signal')\n",
    "plt.hist(y_pred_test[y_test == 0], bins=50, alpha=0.5, label='Background')\n",
    "plt.legend()\n",
    "plt.title(\"DNN Output Scores on Test Set\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88873a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bkg = df_background.copy()\n",
    "df_bkg[\"mass\"] = 500\n",
    "df_bkg[\"y_value\"] = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca78c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sig = signal_df[(signal_df['mass'] == 500) & (signal_df['y_value'] == 200)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ab405",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bkg = df_background.copy()\n",
    "df_bkg[\"mass\"] = 500\n",
    "df_bkg[\"y_value\"] = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b6c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, scaler, features, fallback_mean=None):\n",
    "    df_features_local = df[features].copy()\n",
    "\n",
    "    # Fallback to global mean if passed (e.g., from training data)\n",
    "    if fallback_mean is not None:\n",
    "        df_features_local = df_features_local.fillna(fallback_mean)\n",
    "    else:\n",
    "        df_features_local = df_features_local.fillna(df_features_local.mean())\n",
    "\n",
    "    X = df_features_local.values\n",
    "    X_scaled = scaler.transform(X)\n",
    "    return torch.tensor(X_scaled, dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84795bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a45f6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af4057",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_combined['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95960288",
   "metadata": {},
   "source": [
    "## Fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8ffdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Combine signal and background into a single DataFrame\n",
    "full_df = pd.concat([signal_df, df_background], ignore_index=True)\n",
    "\n",
    "# Define train/test mass points\n",
    "train_masses = [300, 500, 600, 700, 1000]\n",
    "test_masses = [400, 550, 650, 900]\n",
    "\n",
    "# Split by mass\n",
    "train_df = full_df[full_df['mass'].isin(train_masses)]\n",
    "test_df = full_df[full_df['mass'].isin(test_masses)]\n",
    "\n",
    "# Shuffle rows\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Define your feature list (must match your actual feature engineering)\n",
    "features = [col for col in train_df.columns if col not in ['label']]  # include 'mass' and 'y_value' if needed\n",
    "\n",
    "# Prepare inputs and targets\n",
    "X_train = train_df[features].fillna(0).values\n",
    "y_train = train_df['label'].values\n",
    "X_test = test_df[features].fillna(0).values\n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Wrap in datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f999db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d47aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec66a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
