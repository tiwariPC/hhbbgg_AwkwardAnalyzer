{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30409ab8",
   "metadata": {},
   "source": [
    "# Parametrized DNN\n",
    "parametrized DNN \n",
    "1. Plot signal and background seperation\n",
    "2. Include all signals\n",
    "2. check the backgrounds.\n",
    "3. Check the AUC score as this is coming 1\n",
    "4. Improve the training\n",
    "5. include the weight of preselection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3c41b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X300_Y200/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X300_Y300/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X300_Y400/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X300_Y500/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X400_Y300/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X400_Y400/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X400_Y500/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X500_Y400/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X500_Y500/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X550_Y500/nominal/NOTAG_merged.parquet does not exist.\n",
      "Warning: File ../../../output_parquet/final_production_Syst/merged/NMSSM_X600_Y500/nominal/NOTAG_merged.parquet does not exist.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import uproot\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Taking mass X and corresponding Y mass points\n",
    "# mass_points = [300, 400, 500, 550, 600, 650, 700, 900, 1000, 1200, 1400, 1600, 1800, 2000, 2500, 3000, 3500, 4000]  # Example mass points\n",
    "# y_values = [ 60, 70, 80, 90, 95, 100, 125, 150, 200, 300, 400, 500, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2600, 3000, 3500]  # Example Y values\n",
    "\n",
    "mass_points = [300, 400, 500, 550, 600, 650, 700, 900, 1000]  # Example mass points\n",
    "y_values = [ 100, 125, 150, 200, 300, 400, 500]  # Example Y values\n",
    "\n",
    "\n",
    "\n",
    "# Load signal data from Parquet files\n",
    "signal_data = []\n",
    "for mass in mass_points:\n",
    "    for y in y_values:\n",
    "        file_path = f\"../../../output_parquet/final_production_Syst/merged/NMSSM_X{mass}_Y{y}/nominal/NOTAG_merged.parquet\"\n",
    "        \n",
    "        if os.path.exists(file_path):  # Check if file exists\n",
    "            try:\n",
    "                df = pd.read_parquet(file_path)  # Load the Parquet file\n",
    "                df[\"mass\"] = mass  \n",
    "                df[\"y_value\"] = y  # Store Y value if needed\n",
    "                df[\"label\"] = 1  # Assuming signal label\n",
    "                signal_data.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not read {file_path}. Error: {e}\")\n",
    "        else:\n",
    "            print(f\"Warning: File {file_path} does not exist.\")\n",
    "\n",
    "# Combine all signal data into a single DataFrame\n",
    "signal_df = pd.concat(signal_data, ignore_index=True) if signal_data else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ace5651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346281, 853)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9c83e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load background data from ROOT files\n",
    "background_files = [\n",
    "    (\"../../outputfiles/hhbbgg_analyzer-v2-trees.root\", \"/GGJets/preselection\"),\n",
    "    (\"../../outputfiles/hhbbgg_analyzer-v2-trees.root\", \"/GJetPt20To40/preselection\"),\n",
    "    (\"../../outputfiles/hhbbgg_analyzer-v2-trees.root\", \"/GJetPt40/preselection\"),\n",
    "#     (\"../../outputfiles/hhbbgg_analyzer-v2-trees.root\", \"/GGJets/preselection\"),\n",
    "#     (\"../../outputfiles/hhbbgg_analyzer-v2-trees.root\", \"/GJetPt20To40/preselection\"),\n",
    "#     (\"../../outputfiles/hhbbgg_analyzer-v2-trees.root\", \"/GJetPt40/preselection\"),\n",
    "]\n",
    "background_data = []\n",
    "for file_path, tree_name in background_files:\n",
    "    try:\n",
    "        with uproot.open(file_path) as file:\n",
    "            tree = file[tree_name]\n",
    "            df = tree.arrays(library=\"pd\")\n",
    "            df[\"mass\"] = np.random.choice(mass_points, len(df))  # Random mass assignment\n",
    "            df[\"label\"] = 0\n",
    "            background_data.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not read {file_path}. Error: {e}\")\n",
    "\n",
    "df_background = pd.concat(background_data, ignore_index=True) if background_data else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5521617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and labels\n",
    "features = [\n",
    "    'bbgg_eta', 'bbgg_phi', 'lead_pho_phi', 'sublead_pho_eta', \n",
    "    'sublead_pho_phi', 'diphoton_eta', 'diphoton_phi', 'dibjet_eta', 'dibjet_phi', \n",
    "    'lead_bjet_pt', 'sublead_bjet_pt', 'lead_bjet_eta', 'lead_bjet_phi', 'sublead_bjet_eta', \n",
    "    'sublead_bjet_phi', 'sublead_bjet_PNetB', 'lead_bjet_PNetB', 'CosThetaStar_gg', \n",
    "    'CosThetaStar_jj', 'CosThetaStar_CS', 'DeltaR_jg_min', 'pholead_PtOverM', \n",
    "    'phosublead_PtOverM', 'lead_pho_mvaID', 'sublead_pho_mvaID'\n",
    "]\n",
    "features.extend([\"mass\", \"y_value\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90b6ed8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bbgg_eta',\n",
       " 'bbgg_phi',\n",
       " 'lead_pho_phi',\n",
       " 'sublead_pho_eta',\n",
       " 'sublead_pho_phi',\n",
       " 'diphoton_eta',\n",
       " 'diphoton_phi',\n",
       " 'dibjet_eta',\n",
       " 'dibjet_phi',\n",
       " 'lead_bjet_pt',\n",
       " 'sublead_bjet_pt',\n",
       " 'lead_bjet_eta',\n",
       " 'lead_bjet_phi',\n",
       " 'sublead_bjet_eta',\n",
       " 'sublead_bjet_phi',\n",
       " 'sublead_bjet_PNetB',\n",
       " 'lead_bjet_PNetB',\n",
       " 'CosThetaStar_gg',\n",
       " 'CosThetaStar_jj',\n",
       " 'CosThetaStar_CS',\n",
       " 'DeltaR_jg_min',\n",
       " 'pholead_PtOverM',\n",
       " 'phosublead_PtOverM',\n",
       " 'lead_pho_mvaID',\n",
       " 'sublead_pho_mvaID',\n",
       " 'mass',\n",
       " 'y_value']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91c139ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random mass + y_value assignment for backgrounds (ensure this was done earlier!)\n",
    "df_background[\"mass\"] = np.random.choice(mass_points, len(df_background))\n",
    "df_background[\"y_value\"] = np.random.choice(y_values, len(df_background))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "458d6ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reduce background dataset size by random sampling\n",
    "background_fraction = 0.5 #  20% of the background\n",
    "df_background = df_background.sample(frac=background_fraction, random_state=42)\n",
    "\n",
    "# Combine signal and background\n",
    "df_combined = pd.concat([signal_df, df_background], ignore_index=True)\n",
    "\n",
    "# Ensure df_combined is not empty\n",
    "if df_combined.empty:\n",
    "    raise ValueError(\"Error: Combined DataFrame is empty. Check input files.\")\n",
    "\n",
    "# Convert feature data to DataFrame to prevent AttributeError\n",
    "df_features = df_combined[features]\n",
    "\n",
    "# Fill missing values with column mean\n",
    "df_features = df_features.fillna(df_features.mean())\n",
    "\n",
    "# Extract features (X) and labels (y)\n",
    "X = df_features.values\n",
    "y = df_combined[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34ac841f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2011751, 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1feb7f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into 80% train, 20% test (stratified to maintain label distribution)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize features (Fit only on train, transform both)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  \n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create PyTorch datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create Dataloader for training\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Optional: Create test dataloader if you want batch evaluation\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a408f339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 300  400  500  550  600  650  700  900 1000]\n",
      "[1000  300  900  700  500  550  650  600  400]\n"
     ]
    }
   ],
   "source": [
    "# Checking\n",
    "\n",
    "print(signal_df[\"mass\"].unique())\n",
    "print(df_background[\"mass\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2c4ee6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['run', 'lumi', 'event', 'puppiMET_pt', 'puppiMET_phi',\n",
      "       'puppiMET_phiJERDown', 'puppiMET_phiJERUp', 'puppiMET_phiJESDown',\n",
      "       'puppiMET_phiJESUp', 'puppiMET_phiUnclusteredDown',\n",
      "       'puppiMET_phiUnclusteredUp', 'puppiMET_ptJERDown', 'puppiMET_ptJERUp',\n",
      "       'puppiMET_ptJESDown', 'puppiMET_ptJESUp', 'puppiMET_ptUnclusteredDown',\n",
      "       'puppiMET_ptUnclusteredUp', 'puppiMET_sumEt', 'lead_pho_pt',\n",
      "       'lead_pho_eta', 'lead_pho_phi', 'sublead_pho_pt', 'sublead_pho_eta',\n",
      "       'sublead_pho_phi', 'lead_bjet_pt', 'lead_bjet_eta', 'lead_bjet_phi',\n",
      "       'sublead_bjet_pt', 'sublead_bjet_eta', 'sublead_bjet_phi',\n",
      "       'dibjet_mass', 'diphoton_mass', 'bbgg_mass', 'dibjet_pt', 'diphoton_pt',\n",
      "       'bbgg_pt', 'bbgg_eta', 'bbgg_phi', 'weight_central',\n",
      "       'weight_preselection', 'weight_selection', 'weight_srbbgg',\n",
      "       'weight_srbbggMET', 'weight_crbbantigg', 'weight_crantibbgg',\n",
      "       'weight_crantibbantigg', 'weight_sideband', 'weight_idmva_sideband',\n",
      "       'weight_idmva_presel', 'dibjet_eta', 'dibjet_phi', 'diphoton_eta',\n",
      "       'diphoton_phi', 'lead_bjet_PNetB', 'sublead_bjet_PNetB',\n",
      "       'pholead_PtOverM', 'phosublead_PtOverM', 'FirstJet_PtOverM',\n",
      "       'SecondJet_PtOverM', 'CosThetaStar_CS', 'CosThetaStar_jj',\n",
      "       'CosThetaStar_gg', 'DeltaR_jg_min', 'lead_pt_over_diphoton_mass',\n",
      "       'sublead_pt_over_diphoton_mass', 'lead_pt_over_dibjet_mass',\n",
      "       'sublead_pt_over_dibjet_mass', 'diphoton_bbgg_mass', 'dibjet_bbgg_mass',\n",
      "       'lead_pho_mvaID_WP90', 'lead_pho_mvaID_WP80', 'sublead_pho_mvaID_WP90',\n",
      "       'sublead_pho_mvaID_WP80', 'lead_pho_mvaID', 'sublead_pho_mvaID',\n",
      "       'preselection', 'selection', 'srbbgg', 'srbbggMET', 'crantibbgg',\n",
      "       'crbbantigg', 'crantibbantigg', 'sideband', 'idmva_sideband',\n",
      "       'idmva_presel', 'DeltaR_j1g1', 'DeltaR_j2g1', 'DeltaR_j1g2',\n",
      "       'DeltaR_j2g2', 'mass', 'label', 'y_value'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_background.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "258ea236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal y_value: [100 125 150 200 300 400 500]\n",
      "Background y_value: [300 500 400 125 200 150 100]\n"
     ]
    }
   ],
   "source": [
    "print(\"Signal y_value:\", signal_df[\"y_value\"].unique())\n",
    "print(\"Background y_value:\", df_background[\"y_value\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e01c9b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "class ParameterizedDNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ParameterizedDNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "#         self.model = nn.Sequential(\n",
    "#             nn.Linear(input_dim, 32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm1d(32),  # Helps stabilize training\n",
    "#             nn.Dropout(0.2),  # Reduce dropout\n",
    "\n",
    "#             nn.Linear(32, 16),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm1d(16),\n",
    "#             nn.Dropout(0.2),\n",
    "            \n",
    "#             nn.Linear(16, 8),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm1d(8),\n",
    "#             nn.Dropout(0.1),  # Lower dropout to retain information\n",
    "            \n",
    "#             nn.Linear(8, 1)  # Output layer (raw logits)\n",
    "#         )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4df3e456",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mass Distribution')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mass distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(signal_df['mass'], bins=20, alpha=0.5, label='Signal')\n",
    "plt.hist(df_background['mass'], bins=20, alpha=0.5, label='Background')\n",
    "plt.legend()\n",
    "plt.title(\"Mass Distribution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a71b2830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal shape (346281, 853) background.shape (1665470, 92)\n"
     ]
    }
   ],
   "source": [
    "# class balance\n",
    "print(\"signal shape\", signal_df.shape, \"background.shape\", df_background.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78f209a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/sraj/ipykernel_1127207/151203354.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0my_true_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0my_pred_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Initialize model\n",
    "input_dim = X.shape[1]\n",
    "model = ParameterizedDNN(input_dim)\n",
    "criterion = nn.BCEWithLogitsLoss()  # Expecting raw logits\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 50\n",
    "patience = 5\n",
    "best_auc = 0.0\n",
    "patience_counter = 0\n",
    "save_path = \"best_parametric_model.pt\"\n",
    "\n",
    "train_losses, train_accuracies, train_aucs = [], [], []\n",
    "fpr_all, tpr_all, thresholds_all = [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    y_true_train, y_pred_train = [], []\n",
    "\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch).squeeze()\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        y_true_train.extend(y_batch.cpu().numpy())\n",
    "        y_pred_train.extend(torch.sigmoid(outputs).detach().cpu().numpy())\n",
    "\n",
    "    y_pred_train_binary = [1 if p > 0.5 else 0 for p in y_pred_train]\n",
    "    train_accuracy = accuracy_score(y_true_train, y_pred_train_binary)\n",
    "    train_auc = roc_auc_score(y_true_train, y_pred_train)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs_test = model(X_test_tensor.to(device)).squeeze()\n",
    "        y_pred_test = torch.sigmoid(outputs_test).cpu().numpy()\n",
    "        test_loss = criterion(outputs_test, y_test_tensor.to(device)).item()\n",
    "\n",
    "        y_pred_test_binary = [1 if p > 0.5 else 0 for p in y_pred_test]\n",
    "        test_accuracy = accuracy_score(y_test, y_pred_test_binary)\n",
    "        test_auc = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "    train_losses.append(epoch_loss / len(train_dataloader))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_aucs.append(train_auc)\n",
    "\n",
    "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"Train Loss: {train_losses[-1]:.4f} | Train Acc: {train_accuracy:.4f} | Train AUC: {train_auc:.4f}\")\n",
    "    print(f\"Test  Loss: {test_loss:.4f} | Test  Acc: {test_accuracy:.4f} | Test  AUC: {test_auc:.4f}\")\n",
    "\n",
    "    # Early stopping based on test AUC\n",
    "    if test_auc > best_auc:\n",
    "        best_auc = test_auc\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"✅ Model improved. Saved to: {save_path}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement in AUC for {patience_counter} epoch(s).\")\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"⛔ Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# Load best model before proceeding\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "print(\"✅ Best model loaded from checkpoint.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8201ae17",
   "metadata": {},
   "source": [
    "# Next step\n",
    "\n",
    "- [ ] Implement early stopping\n",
    "- [ ] Save the model\n",
    "- [ ] get the dNN score\n",
    "- [ ] Plot it like as in the approval of manos\n",
    "- [ ] Can also plot the signal and background seperations\n",
    "- [ ] Plot AUC\n",
    "- [ ] AUC, ROC\n",
    "- [ ] Signal and background separation\n",
    "- [ ] Check all variables. Include all variables \t\n",
    "- [ ] pNN transformed score\n",
    "- [ ] Plot feature importance \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab81588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Debugging\n",
    "interpolation_mass = 375  # between 300 and 400\n",
    "interpolation_y = 175     # between 150 and 200\n",
    "\n",
    "df_interp = df_background.sample(n=1000, random_state=42).copy()\n",
    "df_interp[\"mass\"] = interpolation_mass\n",
    "df_interp[\"y_value\"] = interpolation_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505f99eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Choose an unseen MX, MY\n",
    "interpolation_mass = 375\n",
    "interpolation_y = 175\n",
    "\n",
    "# 2. Sample and set new param values\n",
    "df_interp = df_background.sample(n=1000, random_state=42).copy()\n",
    "df_interp[\"mass\"] = interpolation_mass\n",
    "df_interp[\"y_value\"] = interpolation_y\n",
    "\n",
    "# 3. Use the same features and preprocessing\n",
    "X_interp = df_interp[features].fillna(df_features.mean()).values\n",
    "X_interp = scaler.transform(X_interp)  # same scaler as training\n",
    "X_interp_tensor = torch.tensor(X_interp, dtype=torch.float32).to(device)\n",
    "\n",
    "# 4. Get model output\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_interp_pred = torch.sigmoid(model(X_interp_tensor)).cpu().numpy()\n",
    "\n",
    "# 5. Plot output distribution\n",
    "plt.hist(y_interp_pred, bins=50, alpha=0.7, label=f\"Interpolated (MX={interpolation_mass}, MY={interpolation_y})\")\n",
    "plt.xlabel(\"DNN Score\")\n",
    "plt.title(\"pNN Output at Interpolated Mass Point\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e7bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance(Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ee408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def compute_permutation_importance(model, X_val, y_val, mass_val, feature_names, device='cpu'):\n",
    "    model.eval()\n",
    "    X_val = X_val.clone().detach().to(device)\n",
    "    mass_val = mass_val.clone().detach().to(device)\n",
    "    y_val_np = y_val.cpu().numpy()\n",
    "\n",
    "    base_preds = torch.sigmoid(model(X_val, mass_val).squeeze()).detach().cpu().numpy()\n",
    "    base_auc = roc_auc_score(y_val_np, base_preds)\n",
    "\n",
    "    importances = []\n",
    "\n",
    "    for i in range(X_val.shape[1]):\n",
    "        scores = []\n",
    "        for _ in range(5):  # repeat for stability\n",
    "            X_shuffled = X_val.clone()\n",
    "            idx = torch.randperm(X_val.shape[0])\n",
    "            X_shuffled[:, i] = X_shuffled[idx, i]\n",
    "            preds = torch.sigmoid(model(X_shuffled, mass_val).squeeze()).detach().cpu().numpy()\n",
    "            auc = roc_auc_score(y_val_np, preds)\n",
    "            scores.append(base_auc - auc)  # performance drop\n",
    "        importances.append(np.mean(scores))\n",
    "\n",
    "    return np.array(importances)\n",
    "\n",
    "# Call the function\n",
    "importances = compute_permutation_importance(model, X_test_tensor, y_test_tensor, mass_test_tensor, feature_names, device=device)\n",
    "\n",
    "# Plot\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.barh(np.array(feature_names)[sorted_idx], importances[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance (AUC drop)\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Feature Importance (Permutation - Parametric DNN)\")\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5206b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c18ec0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41bcc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses.append(epoch_loss / len(train_dataloader))\n",
    "train_accuracies.append(train_accuracy)\n",
    "train_aucs.append(train_auc)\n",
    "\n",
    "# Add test AUC for plotting too\n",
    "if epoch == num_epochs - 1:\n",
    "    plt.plot(train_aucs, label='Train AUC')\n",
    "    plt.axhline(test_auc, color='red', linestyle='--', label='Test AUC (final)')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Train vs. Test AUC\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842b409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_pred_test[y_test == 1], bins=50, alpha=0.5, label='Signal')\n",
    "plt.hist(y_pred_test[y_test == 0], bins=50, alpha=0.5, label='Background')\n",
    "plt.legend()\n",
    "plt.title(\"DNN Output Scores on Test Set\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88873a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bkg = df_background.copy()\n",
    "df_bkg[\"mass\"] = 500\n",
    "df_bkg[\"y_value\"] = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca78c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sig = signal_df[(signal_df['mass'] == 500) & (signal_df['y_value'] == 200)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ab405",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bkg = df_background.copy()\n",
    "df_bkg[\"mass\"] = 500\n",
    "df_bkg[\"y_value\"] = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b6c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, scaler, features, fallback_mean=None):\n",
    "    df_features_local = df[features].copy()\n",
    "\n",
    "    # Fallback to global mean if passed (e.g., from training data)\n",
    "    if fallback_mean is not None:\n",
    "        df_features_local = df_features_local.fillna(fallback_mean)\n",
    "    else:\n",
    "        df_features_local = df_features_local.fillna(df_features_local.mean())\n",
    "\n",
    "    X = df_features_local.values\n",
    "    X_scaled = scaler.transform(X)\n",
    "    return torch.tensor(X_scaled, dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84795bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a45f6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af4057",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_combined['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95960288",
   "metadata": {},
   "source": [
    "## Fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8ffdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Combine signal and background into a single DataFrame\n",
    "full_df = pd.concat([signal_df, df_background], ignore_index=True)\n",
    "\n",
    "# Define train/test mass points\n",
    "train_masses = [300, 500, 600, 700, 1000]\n",
    "test_masses = [400, 550, 650, 900]\n",
    "\n",
    "# Split by mass\n",
    "train_df = full_df[full_df['mass'].isin(train_masses)]\n",
    "test_df = full_df[full_df['mass'].isin(test_masses)]\n",
    "\n",
    "# Shuffle rows\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Define your feature list (must match your actual feature engineering)\n",
    "features = [col for col in train_df.columns if col not in ['label']]  # include 'mass' and 'y_value' if needed\n",
    "\n",
    "# Prepare inputs and targets\n",
    "X_train = train_df[features].fillna(0).values\n",
    "y_train = train_df['label'].values\n",
    "X_test = test_df[features].fillna(0).values\n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Wrap in datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f999db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d47aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec66a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
